{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b54a254-4ad8-40fe-9688-c7111dc99718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594c225f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307e8db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d0c871-a504-4b23-a462-b3400b6863e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1cdad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d62e8db2-a565-4c0e-b7a4-a34bd8db52d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab5edd9f-f0aa-4577-83f9-65a02585a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a9e5dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-google-genai\n",
      "  Using cached langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
      "  Using cached google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.62 (from langchain-google-genai)\n",
      "  Downloading langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting pydantic<3,>=2 (from langchain-google-genai)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai)\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai)\n",
      "  Using cached google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai)\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai)\n",
      "  Using cached protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/yash/Library/IntelliShelf/IntelliShelf/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.4)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai)\n",
      "  Downloading grpcio-1.73.0-cp310-cp310-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting langsmith>=0.3.45 (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai)\n",
      "  Downloading langsmith-0.4.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/yash/Library/IntelliShelf/IntelliShelf/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (6.0.2)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/yash/Library/IntelliShelf/IntelliShelf/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (4.14.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.62->langchain-google-genai)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=2->langchain-google-genai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=2->langchain-google-genai)\n",
      "  Using cached pydantic_core-2.33.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=2->langchain-google-genai)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/yash/Library/IntelliShelf/IntelliShelf/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yash/Library/IntelliShelf/IntelliShelf/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yash/Library/IntelliShelf/IntelliShelf/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yash/Library/IntelliShelf/IntelliShelf/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2025.6.15)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai)\n",
      "  Using cached orjson-3.10.18-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai)\n",
      "  Using cached zstandard-0.23.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/yash/Library/IntelliShelf/IntelliShelf/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.3.0)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Using cached langchain_google_genai-2.1.5-py3-none-any.whl (44 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
      "Downloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "Using cached google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading grpcio-1.73.0-cp310-cp310-macosx_11_0_universal2.whl (10.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.73.0-py3-none-any.whl (14 kB)\n",
      "Downloading langchain_core-0.3.66-py3-none-any.whl (438 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl (425 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp310-cp310-macosx_11_0_arm64.whl (1.9 MB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading langsmith-0.4.1-py3-none-any.whl (364 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached orjson-3.10.18-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (248 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached zstandard-0.23.0-cp310-cp310-macosx_11_0_arm64.whl (633 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: filetype, zstandard, typing-inspection, tenacity, sniffio, pydantic-core, pyasn1, protobuf, packaging, orjson, jsonpointer, h11, grpcio, cachetools, annotated-types, rsa, requests-toolbelt, pydantic, pyasn1-modules, proto-plus, jsonpatch, httpcore, googleapis-common-protos, anyio, httpx, grpcio-status, google-auth, langsmith, google-api-core, langchain-core, google-ai-generativelanguage, langchain-google-genai\n",
      "\u001b[2K  Attempting uninstall: packaging0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/32\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: packaging 25.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/32\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling packaging-25.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/32\u001b[0m [protobuf]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/32\u001b[0m [protobuf]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32/32\u001b[0m [langchain-google-genai]e-ai-generativelanguage]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 anyio-4.9.0 cachetools-5.5.2 filetype-1.2.0 google-ai-generativelanguage-0.6.18 google-api-core-2.25.1 google-auth-2.40.3 googleapis-common-protos-1.70.0 grpcio-1.73.0 grpcio-status-1.73.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.66 langchain-google-genai-2.1.5 langsmith-0.4.1 orjson-3.10.18 packaging-24.2 proto-plus-1.26.1 protobuf-6.31.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.7 pydantic-core-2.33.2 requests-toolbelt-1.0.0 rsa-4.9.1 sniffio-1.3.1 tenacity-9.1.2 typing-inspection-0.4.1 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a32e6362-fb21-4d53-8542-aa88a0654195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\",\n",
    "    google_api_key=GOOGLE_API_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b869fad-2085-4782-8e39-3d5b22ced3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model = ChatGoogleGenerativeAI(model = \"gemini-1.5-flash\", convert_system_message_to_human=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cff8552e-7838-43e7-8b7c-e1e39414e00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "print(model.invoke(\"hi\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "080e0097-28ff-4abf-9118-1d0849cad616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Description** : This sleek, 9-inch black steel flute boasts six finger holes, offering a focused and resonant tone.  Its compact size makes it ideal for travel or close-quarters playing, while the robust steel construction ensures durability and a bright, clear sound. The matte black finish provides a sophisticated aesthetic, making it a striking instrument for both beginners and experienced players. \n",
      "\n",
      " **Features** : \n",
      "\n",
      "* **Class** : flute\n",
      "* **Diameter:** 9 inches\n",
      "* **Holes:** 6\n",
      "* **Color:** Black\n",
      "* **Material:** Steel\n"
     ]
    }
   ],
   "source": [
    "class_name = \"flute\"\n",
    "prop = \"9 inches, 6 holes, black colour, made of steel\"\n",
    "desc = model.invoke(f\"write a decription about {class_name} with properties like {prop}\").content\n",
    "features = model.invoke(f\"make {prop} concise and clear and show it as features\").content\n",
    "print(f\"**Description** : {desc} \\n\\n **Features** : \\n\\n* **Class** : {class_name}\\n{features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8afaed9-6137-432c-86f4-be45e4f14276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "DB_DIR = Path(\"../product_db\")               # folder to hold our files\n",
    "CSV_FILE = DB_DIR / \"products.csv\"\n",
    "# JSON_FILE = DB_DIR / \"products.json\"\n",
    "\n",
    "DB_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def get_next_id(csv_path: Path) -> int:\n",
    "    if not csv_path.exists():\n",
    "        return 0\n",
    "    with open(csv_path, newline='', encoding=\"utf-8\") as f:\n",
    "        return sum(1 for _ in f) - 1       # minus header\n",
    "        \n",
    "\n",
    "def write_product_record(class_name: str, desc: str, features: str):\n",
    "    record = {\n",
    "        \"product_id\": None,     # placeholder\n",
    "        \"class\": class_name,\n",
    "        \"description\": desc.strip(),\n",
    "        \"features\": features.strip()\n",
    "    }\n",
    "    next_id = get_next_id(CSV_FILE)\n",
    "    record[\"product_id\"] = next_id\n",
    "\n",
    "    # append to CSV (header handled automatically)\n",
    "    write_header = not CSV_FILE.exists()\n",
    "    with open(CSV_FILE, \"a\", newline='', encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=record.keys())\n",
    "        if write_header:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07fe5747-7642-4aa2-b4e9-c271883e8d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"tabla\"\n",
    "prop = \"3 feet diameter, 2.5 feet tall, made of african wood\"\n",
    "desc = model.invoke(f\"write a description about {class_name} with properties like {prop}\").content\n",
    "features = model.invoke(f\"make {prop} concise and clear and show it as points\").content\n",
    "write_product_record(class_name, desc, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba16f766-94d9-437f-9dca-66634588f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0e01cec-d4c4-4c69-8dd2-53d9b3598d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* **Diameter:** 3 feet\n",
      "* **Height:** 2.5 feet\n",
      "* **Material:** African wood\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DB_DIR / \"products.csv\")\n",
    "print(df[\"features\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de2c0796-0259-4dcd-8dcb-df22c24361bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This imposing tabla, a true behemoth of its kind, boasts a diameter of three feet, its resonant body rising to a height of two and a half feet. Crafted from richly hued African wood, the instrument's surface displays the beautiful, natural grain patterns unique to its origin.  The sheer size suggests a powerful, deep tone, capable of filling even the largest spaces. The weight, undoubtedly substantial, hints at a density and resonance that would be exceptional. This isn't just a tabla; it's a statement piece, a commanding presence that speaks of both masterful craftsmanship and the raw power of the African timber from which it's born.\n"
     ]
    }
   ],
   "source": [
    "print(df[\"description\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58627286-1869-496c-aa1c-e9ae1741834b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(df[\"product_id\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ec5e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device - mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE=\"cude\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE=\"mps\"\n",
    "else:\n",
    "    DEVICE=\"cpu\"\n",
    "\n",
    "print(f\"Using Device - {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef4a81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['drum', 'flute', 'guitar', 'tabla', 'violin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b66cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/Users/yash/Library/IntelliShelf/dataset/images/violin/0002.jpg\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f465007d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted index: 4   confidence: 0.999983549118042\n",
      "violin\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "classify_model = torch.load(\"../model/classify.pth\", map_location=DEVICE, weights_only=False)\n",
    "classify_model.eval()                            \n",
    "classify_model.to(DEVICE)                     \n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "                 \n",
    "image = Image.open(img_path).convert(\"RGB\")\n",
    "input_tensor = preprocess(image).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = classify_model(input_tensor)\n",
    "    probs  = torch.softmax(logits, dim=1)\n",
    "\n",
    "top_prob, pred_idx = probs.max(dim=1)\n",
    "print(\"Predicted index:\", pred_idx.item(), \"  confidence:\", top_prob.item())\n",
    "class_name = classes[pred_idx.item()]\n",
    "print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aac70f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/yash/Library/IntelliShelf/dataset/images/violin/0002.jpg\n",
      "✅ Clean (no defect ≥ 0.25).\n",
      "Next you have to write properties (features) of your product.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. configure paths and confidence threshold\n",
    "# ------------------------------------------------------------------\n",
    "MODEL_PATH   = Path(\"/Users/yash/Library/IntelliShelf/runs/detect/train2/weights/best.pt\")   # your trained weights\n",
    "DEFECT_CLASS = 0                 # index you used for “defect” in defect.yaml\n",
    "CONF_THRES   = 0.25              # treat predictions above this as valid\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. load model once\n",
    "# ------------------------------------------------------------------\n",
    "defect_model = YOLO(MODEL_PATH)\n",
    "\n",
    "def is_damaged(image_path: str | Path, conf_thresh: float = CONF_THRES) -> tuple[bool, float]:\n",
    "    \"\"\"\n",
    "    Returns (damaged?, highest_defect_confidence)\n",
    "    \"\"\"\n",
    "    results = defect_model.predict(source=str(image_path), imgsz=512, conf=conf_thresh, verbose=False)\n",
    "    boxes = results[0].boxes\n",
    "\n",
    "    # find max confidence for defect class\n",
    "    max_conf = 0.0\n",
    "    for b in boxes:\n",
    "        if int(b.cls[0]) == DEFECT_CLASS:\n",
    "            max_conf = max(max_conf, float(b.conf[0]))\n",
    "\n",
    "    damaged = max_conf >= conf_thresh\n",
    "    return damaged, max_conf\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. test it\n",
    "# ------------------------------------------------------------------\n",
    "damaged, conf = is_damaged(img_path)\n",
    "\n",
    "print(f\"Image: {img_path}\")\n",
    "if damaged:\n",
    "    print(f\"🚨 Defected (confidence {conf:.2f}).\\nPlease upload another image.\")\n",
    "else:\n",
    "    print(f\"✅ Clean (no defect ≥ {CONF_THRES}).\\nNext you have to write properties (features) of your product.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce1fdfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "DB_DIR = Path(\"../product_db\")               # folder to hold our files\n",
    "CSV_FILE = DB_DIR / \"products.csv\"\n",
    "# JSON_FILE = DB_DIR / \"products.json\"\n",
    "\n",
    "DB_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def get_next_id(csv_path: Path) -> int:\n",
    "    if not csv_path.exists():\n",
    "        return 0\n",
    "    with open(csv_path, newline='', encoding=\"utf-8\") as f:\n",
    "        return sum(1 for _ in f) - 1       # minus header\n",
    "        \n",
    "\n",
    "def write_product_record(class_name: str, desc: str, features: str, img_path: str):\n",
    "    record = {\n",
    "        \"product_id\": None,     # placeholder\n",
    "        \"class\": class_name,\n",
    "        \"description\": desc.strip(),\n",
    "        \"features\": features.strip(),\n",
    "        \"image_path\": img_path\n",
    "    }\n",
    "    next_id = get_next_id(CSV_FILE)\n",
    "    record[\"product_id\"] = next_id\n",
    "\n",
    "    # append to CSV (header handled automatically)\n",
    "    write_header = not CSV_FILE.exists()\n",
    "    with open(CSV_FILE, \"a\", newline='', encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=record.keys())\n",
    "        if write_header:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c795b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yash/Library/IntelliShelf/IntelliShelf/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:424: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    }
   ],
   "source": [
    "prop = \"3 feet diameter, 2.5 feet tall, made of african wood\"\n",
    "desc = model.invoke(f\"write a description about {class_name} with properties like {prop}\").content\n",
    "features = model.invoke(f\"make {prop} concise and clear and show it as points\").content\n",
    "write_product_record(class_name, desc, features, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7881a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>class</th>\n",
       "      <th>description</th>\n",
       "      <th>features</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>violin</td>\n",
       "      <td>This isn't a violin; it's a colossal, imposing...</td>\n",
       "      <td>* Diameter: 3 feet\\n* Height: 2.5 feet\\n* Mate...</td>\n",
       "      <td>/Users/yash/Library/IntelliShelf/dataset/image...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id   class                                        description  \\\n",
       "0           0  violin  This isn't a violin; it's a colossal, imposing...   \n",
       "\n",
       "                                            features  \\\n",
       "0  * Diameter: 3 feet\\n* Height: 2.5 feet\\n* Mate...   \n",
       "\n",
       "                                          image_path  \n",
       "0  /Users/yash/Library/IntelliShelf/dataset/image...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"../product_db/products.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4422cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yash/Library/IntelliShelf/dataset/images/violin/0002.jpg\n"
     ]
    }
   ],
   "source": [
    "print(df[\"image_path\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4ca630e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Diameter: 3 feet\n",
      "* Height: 2.5 feet\n",
      "* Material: African wood\n"
     ]
    }
   ],
   "source": [
    "print(df[\"features\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e50faa3-f8aa-4a05-8f74-8aeba8db04ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
